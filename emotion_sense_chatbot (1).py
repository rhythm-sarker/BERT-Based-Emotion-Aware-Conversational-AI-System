# -*- coding: utf-8 -*-
"""Emotion_Sense-Chatbot.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XhY8cuVxpK3UD-xbvFeuJAcgX3WlWk9_
"""

!pip install -q transformers datasets evaluate scikit-learn pandas torch matplotlib

import pandas as pd

df = pd.read_csv("intent_data_extended.csv")
df.head()

from sklearn.preprocessing import LabelEncoder

label_encoder = LabelEncoder()
df["label_id"] = label_encoder.fit_transform(df["label"])
num_labels = len(label_encoder.classes_)

from sklearn.model_selection import train_test_split

train_df, val_df = train_test_split(
    df,
    test_size=0.2,
    stratify=df["label_id"],
    random_state=42
)

from datasets import Dataset

train_dataset = Dataset.from_pandas(train_df[["text", "label_id"]])
val_dataset = Dataset.from_pandas(val_df[["text", "label_id"]])

from transformers import BertTokenizer

tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")

def tokenize(batch):
    return tokenizer(batch["text"], padding="max_length", truncation=True, max_length=64)

train_dataset = train_dataset.map(tokenize, batched=True)
val_dataset = val_dataset.map(tokenize, batched=True)

train_dataset = train_dataset.rename_column("label_id", "labels")
val_dataset = val_dataset.rename_column("label_id", "labels")

train_dataset.set_format("torch")
val_dataset.set_format("torch")

from transformers import BertForSequenceClassification

model = BertForSequenceClassification.from_pretrained(
    "bert-base-uncased",
    num_labels=num_labels
)

from transformers import TrainingArguments

training_args = TrainingArguments(
    output_dir="./bert_results",
    eval_strategy="epoch",
    save_strategy="epoch",
    learning_rate=2e-5,
    per_device_train_batch_size=16,
    per_device_eval_batch_size=16,
    num_train_epochs=5,
    weight_decay=0.01,
    load_best_model_at_end=True,
    metric_for_best_model="f1"
)

import evaluate, numpy as np

accuracy = evaluate.load("accuracy")
f1 = evaluate.load("f1")

def compute_metrics(pred):
    logits, labels = pred
    preds = np.argmax(logits, axis=1)
    return {
        "accuracy": accuracy.compute(predictions=preds, references=labels)["accuracy"],
        "f1": f1.compute(predictions=preds, references=labels, average="weighted")["f1"]
    }

from transformers import Trainer

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset,
    tokenizer=tokenizer,
    compute_metrics=compute_metrics
)

trainer.train()
trainer.evaluate()

model.save_pretrained("bert_emotion_model")
tokenizer.save_pretrained("bert_emotion_model")

import joblib
joblib.dump(label_encoder, "label_encoder.pkl")

import torch
import torch.nn.functional as F
from transformers import BertTokenizer, BertForSequenceClassification
import joblib

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

tokenizer = BertTokenizer.from_pretrained("bert_emotion_model")
model = BertForSequenceClassification.from_pretrained("bert_emotion_model")
label_encoder = joblib.load("label_encoder.pkl")

model.to(device)
model.eval()

def predict_emotion_with_confidence(text):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True)
    inputs = {k: v.to(device) for k, v in inputs.items()}

    with torch.no_grad():
        outputs = model(**inputs)
        probs = F.softmax(outputs.logits, dim=1)

    conf, pred = torch.max(probs, dim=1)
    emotion = label_encoder.inverse_transform([pred.item()])[0]

    return emotion, conf.item()

def chatbot_response(text):
    emotion, confidence = predict_emotion_with_confidence(text)

    responses = {
        "happy": "I'm glad you're feeling happy üòä",
        "sad": "I'm here for you üòî",
        "angry": "Let‚Äôs take a deep breath üò†",
        "neutral": "Tell me more."
    }

    return responses.get(emotion, "I understand."), confidence

print("ü§ñ Chatbot is running (type 'bye' to exit)\n")

while True:
    user_input = input("You: ")

    if user_input.lower() in ["bye", "exit", "quit"]:
        print("Chatbot: Take care ‚ù§Ô∏è")
        break

    reply, conf = chatbot_response(user_input)
    print(f"Chatbot: {reply} (confidence: {conf:.2f})")

